

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from scipy.stats import entropy, pearsonr, spearmanr
from scipy.spatial.distance import jensenshannon
from scipy.stats import wasserstein_distance
import time
import pandas as pd
from torch.optim.lr_scheduler import ReduceLROnPlateau




DATA_DIR = os.path.expanduser("~/thesis_data")
NYP_DIR = os.path.join(DATA_DIR, 'npy')
CSV_DIR = os.path.join(DATA_DIR, 'csv')
MODEL_SAVE = os.path.join(DATA_DIR, "models", '0703MLP2-0.7.pth')
BATCH_SIZE = 32
LR = 1e-4
EPOCHS = 30
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
PATIENCE = 3
best_val_loss = float('inf')
patience_counter = 0
log_list = []

class MeanFeatureDataset(Dataset):
    def __init__(self, feat_npy, label_npy, nimg_npy):
        self.feats = np.load(feat_npy)    # [N,2048]
        self.labels = np.load(label_npy)  # [N,21]
        self.n_imgs = np.load(nimg_npy)   # [N,]
    def __len__(self):
        return len(self.feats)
    def __getitem__(self, idx):
        return torch.tensor(self.feats[idx], dtype=torch.float32), \
               torch.tensor(self.labels[idx], dtype=torch.float32), \
               torch.tensor(self.n_imgs[idx], dtype=torch.float32)

def compute_class_weights(freq, gamma=0.5):#try with 0.3,0.5,0.7
    freq = freq + 1e-6
    w = 1 / np.log1p(freq)
    w = w / w.mean()
    w = w ** gamma
    return torch.tensor(w, dtype=torch.float32).to(DEVICE)

train_labels_csv = os.path.join(CSV_DIR, 'train_labels.csv')
df = pd.read_csv(train_labels_csv)
label_cols = [col for col in df.columns if col not in ['image_name', 'owner', 'split']]
freq = df[label_cols].sum().values
WEIGHT_GAMMA = 0.7  # 每次实验换成0.3、0.5、0.7
class_weights = compute_class_weights(freq, gamma=WEIGHT_GAMMA)

#use weigthed class
class WeightedKLDivLoss(nn.Module):
    def __init__(self, class_weights, reduction='batchmean'):
        super().__init__()
        self.class_weights = class_weights  # shape: [n_class]
        self.reduction = reduction
        self.kl = nn.KLDivLoss(reduction='none')
    def forward(self, input, target):
        loss = self.kl(input, target)  # shape [batch, class]
        weighted = loss * self.class_weights
        if self.reduction == 'batchmean':
            return weighted.sum() / input.size(0)
        else:
            return weighted.mean()

TRAIN_FEATURE_NPY = f'{NYP_DIR}/train_mean_features.npy'
TRAIN_LABEL_NPY   = f'{NYP_DIR}/train_mean_labels.npy'
TRAIN_NIMG_NPY    = f'{NYP_DIR}/train_n_imgs.npy'
VAL_FEATURE_NPY   = f'{NYP_DIR}/val_mean_features.npy'
VAL_LABEL_NPY     = f'{NYP_DIR}/val_mean_labels.npy'
VAL_NIMG_NPY      = f'{NYP_DIR}/val_n_imgs.npy'

train_set = MeanFeatureDataset(TRAIN_FEATURE_NPY, TRAIN_LABEL_NPY, TRAIN_NIMG_NPY)
val_set   = MeanFeatureDataset(VAL_FEATURE_NPY, VAL_LABEL_NPY, VAL_NIMG_NPY)
train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)

#mlp
class MLPHead(nn.Module):
    def __init__(self, in_dim=2048, num_classes=21):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(in_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )
    def forward(self, x):
        return self.fc(x)

model = MLPHead().to(DEVICE)
optimizer = optim.Adam(model.parameters(), lr=LR)
criterion = WeightedKLDivLoss(class_weights)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True, min_lr=1e-6)


#evaluation 

def eval_metrics(probs, targets, topk=3):
    results = {}
    eps = 1e-10
    KLs = [entropy(t + eps, p + eps) for t, p in zip(targets, probs)]
    results['KL(mean)'] = np.mean(KLs)
    JSs = [jensenshannon(t + eps, p + eps)**2 for t, p in zip(targets, probs)]
    results['JS(mean)'] = np.mean(JSs)
    # --- EMD (Wasserstein-1) ---
    EMDs = [wasserstein_distance(t, p) for t, p in zip(targets, probs)]
    results['EMD(mean)'] = np.mean(EMDs)
    cosines = [
        np.dot(t, p) / (np.linalg.norm(t) * np.linalg.norm(p) + 1e-8)
        for t, p in zip(targets, probs)
    ]
    results['Cosine(mean)'] = np.mean(cosines)
    r_pearson = pearsonr(targets.flatten(), probs.flatten())[0]
    r_spearman = spearmanr(targets.flatten(), probs.flatten())[0]
    results['Pearson_r'] = r_pearson
    results['Spearman_r'] = r_spearman
    # --- Top-k Accuracy (k=1,3) ---
    def topk_acc(k):
        pred_topk = np.argpartition(probs, -k, axis=1)[:, -k:]
        true_topk = np.argpartition(targets, -k, axis=1)[:, -k:]
        hits = [len(set(pred_topk[i]) & set(true_topk[i])) > 0 for i in range(len(probs))]
        return np.mean(hits)
    results['Top-1 Acc'] = topk_acc(1)
    results['Top-3 Acc'] = topk_acc(3)
    try:
        from sklearn.metrics import average_precision_score
        results['mAP@all'] = average_precision_score(targets, probs, average='macro')
    except:
        results['mAP@all'] = np.nan
    per_class_kl = np.mean([
        entropy(targets[:,i]+eps, probs[:,i]+eps)
        for i in range(targets.shape[1])
    ])
    results['Per-class KL(mean)'] = per_class_kl
    return results

def get_all_metrics(logits, labels):
    probs = torch.softmax(logits, dim=1).cpu().numpy()
    targets = labels.cpu().numpy()
    return eval_metrics(probs, targets)

#train start

for epoch in range(EPOCHS):
    t0 = time.time()
    model.train()
    total_loss = 0.0
    for feats, labels, n_imgs in train_loader:
        feats, labels = feats.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        logits = model(feats)
        log_probs = torch.log_softmax(logits, dim=1)
        loss = criterion(log_probs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * feats.size(0)
    avg_loss = total_loss / len(train_set)
    t1 = time.time()


    model.eval()
    all_logits_tr, all_labels_tr = [], []
    with torch.no_grad():
        for feats, labels, n_imgs in train_loader:
            feats, labels = feats.to(DEVICE), labels.to(DEVICE)
            logits = model(feats)
            all_logits_tr.append(logits.cpu())
            all_labels_tr.append(labels.cpu())
    all_logits_tr = torch.cat(all_logits_tr)
    all_labels_tr = torch.cat(all_labels_tr)
    metrics_train = get_all_metrics(all_logits_tr, all_labels_tr)


    all_logits, all_labels = [], []
    with torch.no_grad():
        for feats, labels, n_imgs in val_loader:
            feats, labels = feats.to(DEVICE), labels.to(DEVICE)
            logits = model(feats)
            all_logits.append(logits.cpu())
            all_labels.append(labels.cpu())
    all_logits = torch.cat(all_logits)
    all_labels = torch.cat(all_labels)
    metrics_val = get_all_metrics(all_logits, all_labels)


    print(f"\nEpoch {epoch+1:2d} | Train Loss: {avg_loss:.4f} | Time: {t1-t0:.1f}s")
    print("Train metrics:")
    for k, v in metrics_train.items():
        print(f"  {k:18s}: {v:.4f}")
    print("Val metrics:")
    for k, v in metrics_val.items():
        print(f"  {k:18s}: {v:.4f}")


#record
    log_entry = {
        "epoch": epoch+1, "train_loss": avg_loss, "val_loss": metrics_val['KL(mean)'], "time": t1-t0
    }
    for k, v in metrics_train.items():
        log_entry[f"train_{k}"] = v
    for k, v in metrics_val.items():
        log_entry[f"val_{k}"] = v
    log_list.append(log_entry)
    pd.DataFrame(log_list).to_csv(os.path.join(CSV_DIR, 'log_0703MLP2-0.7.csv'), index=False)

 
    if metrics_val['KL(mean)'] < best_val_loss:
        best_val_loss = metrics_val['KL(mean)']
        patience_counter = 0
        torch.save(model.state_dict(), MODEL_SAVE)
        print("Best model saved as 0703MLP2-0.7.pth")
    else:
        patience_counter += 1
        print(f"Early stopping patience: {patience_counter}/{PATIENCE}")
        if patience_counter >= PATIENCE:
            print("Early stopping triggered. Training finished.")
            break
   

    scheduler.step(metrics_val['KL(mean)'])
